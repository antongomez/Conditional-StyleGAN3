# This code is part of the EMViT-DDPM project and was authored by Victor Barreiro.


"""
This script evaluates the quality of synthetic hyperspectral images generated by a diffusion model.
It calculates FrÃ©chet Inception Distance (FID), Precision, and Recall metrics by comparing
a pool of generated images against a real dataset.

The script performs the following steps:
1.  Parses command-line arguments to configure the evaluation (e.g., model path, dataset, generation parameters).
2.  Loads the real hyperspectral dataset and the pre-trained diffusion model.
3.  Sets up an experiment folder to save results and logs.
4.  Generates a set of synthetic image examples for visual inspection.
5.  Creates a larger pool of synthetic images for quantitative evaluation.
6.  Optionally normalizes the synthetic data to match the statistical properties (mean, std) of the real data.
7.  If a model for FID is provided, it calculates the FID score between real and synthetic samples.
8.  Calculates k-NN based Precision and Recall to assess the fidelity and diversity of the generated samples.
9.  Logs all configurations, results, and statistics to a file.
"""

##########################################################################################
# ------------------------------------ GLOBAL IMPORTS ----------------------------------#
##########################################################################################


import argparse
import os
import random
import time

import numpy as np
import torch
from tqdm import tqdm

import dnnlib
from gen_images import generate_images
from manifold_metrics import calculate_fid, compute_precision_recall
from multispectral_utils import build_dataset, init_dataset_kwargs


def get_device():
    """Returns the available device (GPU or CPU)."""
    return torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


def ensure_reproducibility(seed):
    """Sets the random seed for reproducibility and configures PyTorch for deterministic behavior."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

    if cuda == False:
        torch.use_deterministic_algorithms(True)
        g = torch.Generator()
        g.manual_seed(SEED)
    else:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


def one_hot_to_index(one_hot):
    """Convert one-hot encoded labels to integer indices."""
    return int(np.argmax(one_hot))


def get_train_samples(dataset, sampling, experiment_index, num_experiments):

    rev_label_map = dataset.get_rev_label_map()

    # Set a counter per class
    counter = dict()
    for class_idx in rev_label_map.keys():
        counter[class_idx] = sampling

    # Iterate through the dataset saving the indices of each class separately
    class_indexes = dict()
    for class_idx in rev_label_map.keys():
        class_indexes[class_idx] = []
    # Start at a random index and move through the set until the data is covered
    starting_index = np.random.randint(0, len(dataset))
    total = sum(counter.values())
    pbar = tqdm(total=total, desc=f"Experiment {experiment_index+1}/{num_experiments} - Gathering real samples")

    idx = starting_index
    while sum(counter.values()) != 0:
        label = one_hot_to_index(dataset[idx][1])

        if counter[label] > 0:
            class_indexes[label].append(idx)
            counter[label] -= 1
            pbar.update(1)

        idx = (idx + 1) % len(dataset)

    pbar.close()

    assert sum(counter.values()) == 0, f"Not all classes were filled correctly: {counter}"

    samples = []
    for class_idx in class_indexes.keys():
        samples.extend([dataset[j][0] for j in class_indexes[class_idx]])  # do not store the label

    return samples


def obtain_samples_from_pool(pool, classes, num_samples):
    """Obtain samples from the pool for the specified classes."""
    samples = []
    for class_idx in classes:
        class_samples = pool[class_idx]
        selected_indices = np.random.choice(class_samples.shape[0], num_samples, replace=False)
        for idx in selected_indices:
            samples.append((class_samples[idx], class_idx))
    return samples


def get_synthetic_samples(pool, classes, num_samples):
    samples = []
    for class_idx in classes:
        samples_class = obtain_samples_from_pool(pool, [class_idx], num_samples)
        samples_class = [np.transpose(sample[0].cpu().numpy(), (2, 0, 1)) for sample in samples_class]
        samples.extend(samples_class)
    return samples


parser = argparse.ArgumentParser(description="Hyperspectral Image Classification")

# Add arguments
# fmt: off
parser.add_argument("--network-pkl",        help="Model to use",                                                                type=str, required=True)
parser.add_argument("--patch-size",         help="Patch size",                                                                  type=int, default=32)
parser.add_argument("--fid-model-path",     help="Model to calculate FID",                                                      type=str, default=None)
# Normalize
parser.add_argument("--normalize",          help="Normalization applied",                                                       type=int, default=-1)
# Pool size parameter
parser.add_argument("--pool-size",          help="Pool size for the generated images",                                          type=int, default=200)
parser.add_argument("--pool-path",          help="Path to the pool of images. If there is one to use in place to generate it.", type=str, default="None")
# Dataset parameters
parser.add_argument("--input-path",         help="Path to the input multispectral dataset",                                     type=str, default="./data")
parser.add_argument("--filename",           help="Base filename (without extension)",                                           type=str, required=True)
parser.add_argument("--dataset-seed",       help="Random seed for dataset splitting",                                           type=int, default=0)
parser.add_argument("--batch-size",         help="Batch size for data loaders",                                                 type=int, default=256)
parser.add_argument("--synthetic-norm",     help="Wheter to normalize the synthetic images or not",                             action="store_true", default=False)
# fmt: on

args = parser.parse_args()

device = get_device()
cuda = device.type == "cuda"

SEED = 42
ensure_reproducibility(seed=SEED)


##########################################################################################
# -------------------------------------- DATA LOADING ---------------------------------- #
##########################################################################################

input_dir = os.path.join(args.input_path, args.filename)
output_dir = os.path.join(args.input_path, args.filename, "patches")

# Build datasets
datasets = dict()
for split_key in ["train", "val", "test"]:
    # Build file names for datasets zips
    dataset_seed_suffix = "" if args.dataset_seed == 0 else f"_{args.dataset_seed}"
    dataset_zip_path = os.path.join(input_dir, f"{args.filename}_{split_key}{dataset_seed_suffix}.zip")
    # Initialize dataset kwargs
    dataset_kwargs, _ = init_dataset_kwargs(data=dataset_zip_path)
    dataset_kwargs.use_label_map = True
    # Build dataset and dataloader
    datasets[split_key], _ = build_dataset(
        dataset_kwargs=dataset_kwargs,
        data_loader_kwargs=dnnlib.EasyDict(),
        batch_size=args.batch_size,
    )

# {<index>: <label> - 1}; <index> between 0 and num_classes - 1; <label> true label in the dataset
label_map = datasets["train"].get_label_map()


##########################################################################################
# ------------------------- EXAMPLES OF SYNTHETIC GENERATIONS -------------------------- #
##########################################################################################

class_labels = list(label_map.values())

sample_out_dir = "./out/samples"
os.makedirs(sample_out_dir, exist_ok=True)

_ = generate_images.callback(
    network_pkl=args.network_pkl,
    seeds=[0],  # use always the same seed for reproducibility
    truncation_psi=1.0,
    noise_mode="const",
    outdir=sample_out_dir,
    translate=(0.0, 0.0),
    rotate=0.0,
    class_idx=None,  # no used
    classes=class_labels,
    num_images_per_class=10,
    save_images=True,
    no_rgb=False,
    no_int8=False,
)

##########################################################################################
# ---------------------------------- IMAGE POOL GENERATION ----------------------------- #
##########################################################################################

samples = generate_images.callback(
    network_pkl=args.network_pkl,
    seeds=[SEED],  # use always the same seed for reproducibility
    truncation_psi=1.0,
    noise_mode="const",
    outdir=sample_out_dir,  # no used as save_images is False
    translate=(0.0, 0.0),
    rotate=0.0,
    class_idx=None,  # no used
    classes=class_labels,
    num_images_per_class=args.pool_size,
    save_images=False,
    no_rgb=True,
    no_int8=True,
)

# Save the samples in a dictionary, one key for each class
pool = dict()
for i, class_idx in enumerate(class_labels):
    pool[class_idx] = samples[i * args.pool_size : (i + 1) * args.pool_size, :, :, :]

# Compute pools stats, i.e., mean and std of the pool
pool_mean = samples.mean().item()
pool_var = samples.var().item()
pool_std = np.sqrt(pool_var)
print("Pool stats:")
print(f"Mean: {pool_mean:.6f}")
print(f"Std: {pool_std:.6f}")

if True:
    # Compute real dataset stats, i.e., mean and std of the real dataset
    means = {"train": 0, "test": 0}
    vars = {"train": 0, "test": 0}
    stds = {"train": 0, "test": 0}

    for split in ["train", "test"]:
        for image, label in datasets[split]:
            means[split] += image.mean()
        means[split] = means[split] / len(datasets[split])
        for image, label in datasets[split]:
            vars[split] += (image.mean() - means[split]) ** 2
        vars[split] = vars[split] / len(datasets[split])
        stds[split] = np.sqrt(vars[split])
        print(f"{split.capitalize()} set stats:")
        print(f"Mean: {means[split]:.6f}")
        print(f"Std: {stds[split]:.6f}")

    scale_factor = stds["train"] / pool_std
    shift = pool_mean - means["train"]
    print(f"Scale factor: {scale_factor:.6f}")
    print(f"Shift: {shift:.6f}")

    if args.synthetic_norm:
        # Normalize the image pool
        for class_idx in pool.keys():
            pool[class_idx] = (pool[class_idx] - shift) * scale_factor

        # Concatenate all samples to compute the new stats
        normalized_samples = torch.cat(list(pool.values()), dim=0)
        pool_mean = normalized_samples.mean().item()
        pool_var = normalized_samples.var().item()
        pool_std = np.sqrt(pool_var)
        print("Pool NORMALIZED stats")
        print("Pool stats:")
        print(f"Mean: {pool_mean:.6f}")
        print(f"Std: {pool_std:.6f}")


##########################################################################################
# ------------------------------------ COMPUTE FID ------------------------------------- #
##########################################################################################


if args.fid_model_path is not None:
    # Load the serialized object with torch judge.pt
    # judge_model = torch.load(args.fid_model_path).to(device)
    judge_model = None

    print("Calculating FID")

    sampling = 10
    assert sampling <= args.pool_size, f"Sampling ({sampling}) must be less or equal than pool size ({args.pool_size})"
    experiments = 5

    fids = []
    times = []

    rev_label_map = datasets["train"].get_rev_label_map()

    for i in range(experiments):
        start = time.time()

        examples_1 = get_train_samples(datasets["train"], sampling, i, experiments)
        examples_2 = get_synthetic_samples(pool, class_labels, sampling)

        fids.append(calculate_fid(judge_model, examples_1, examples_2, device=device))
        end = time.time()
        times.append(end - start)

    # Show the results
    print(f"FID: {np.mean(fids):.6f} +/- {np.std(fids):.6f}")
    print(f"Time: {np.mean(times):.6f} +/- {np.std(times):.6f}")

##########################################################################################
# ---------------------------- COMPUTE PRECISION AND RECALL -----------------------------#
##########################################################################################

experiments = 5

precision_mean = []
recall_mean = []
precision_std = []
recall_std = []

times_mean = []
times_std = []

sampling = 20  # 200

results_precission = []
results_recall = []
result_times = []

# Load the serialized torch object (judge model)
# judge_model = torch.load(args.fid_model_path).to(device)
judge_model = None  # REMOVE WHEN THE MODEL IS AVAILABLE

for i in range(experiments):
    start = time.time()

    examples_1 = get_train_samples(datasets["train"], sampling, i, experiments)
    examples_2 = get_synthetic_samples(pool, class_labels, sampling)

    # Extract features using the judge model
    features_1 = []
    features_2 = []

    # precision, recall = compute_precision_recall(judge_model, examples_1, examples_2, device=device)
    precision = recall = 0.0  # REMOVE WHEN THE MODEL IS AVAILABLE

    results_precission.append(precision)
    results_recall.append(recall)
    result_times.append(time.time() - start)


print(f"Precision: {np.mean(results_precission):.6f} +/- {np.std(results_precission):.6f}")
print(f"Recall: {np.mean(results_recall):.6f} +/- {np.std(results_recall):.6f}")
print(f"Time: {np.mean(result_times):.6f} +/- {np.std(result_times):.6f}")
