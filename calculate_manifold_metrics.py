# This code is part of the EMViT-DDPM project and was authored by Victor Barreiro.


"""
This script evaluates the quality of synthetic hyperspectral images generated by a diffusion model.
It calculates Fr√©chet Inception Distance (FID), Precision, and Recall metrics by comparing
a pool of generated images against a real dataset.

The script performs the following steps:
1.  Parses command-line arguments to configure the evaluation (e.g., model path, dataset, generation parameters).
2.  Loads the real hyperspectral dataset and the pre-trained diffusion model.
3.  Sets up an experiment folder to save results and logs.
4.  Generates a set of synthetic image examples for visual inspection.
5.  Creates a larger pool of synthetic images for quantitative evaluation.
6.  Optionally normalizes the synthetic data to match the statistical properties (mean, std) of the real data.
7.  If a model for FID is provided, it calculates the FID score between real and synthetic samples.
8.  Calculates k-NN based Precision and Recall to assess the fidelity and diversity of the generated samples.
9.  Logs all configurations, results, and statistics to a file.
"""

##########################################################################################
# ------------------------------------ GLOBAL IMPORTS ----------------------------------#
##########################################################################################


import argparse
import os
import random
import time

import numpy as np
import torch
from torch.utils.data import DataLoader, Subset
from tqdm import tqdm

import dnnlib
from gen_images import generate_images
from manifold_metrics import HYPERPARAMS, CNN2D_Residual, DatasetMock, calculate_fid, compute_precision_recall
from multispectral_utils import build_dataset, init_dataset_kwargs


def get_device():
    """Returns the available device (GPU or CPU)."""
    return torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


def ensure_reproducibility(seed):
    """Sets the random seed for reproducibility and configures PyTorch for deterministic behavior."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

    if cuda == False:
        torch.use_deterministic_algorithms(True)
        g = torch.Generator()
        g.manual_seed(SEED)
    else:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


def get_train_samples(dataset, sampling, num_workers=3):

    raw_labels = dataset._get_raw_labels()
    rev_label_map = dataset.get_rev_label_map()  # {raw_label: internal_index}

    if not rev_label_map:
        rev_label_map = {i: i for i in range(dataset.label_dim)}

    # Build the map of {internal_class_idx: [list of dataset indices]}
    # This is much faster than iterating the dataset with __getitem__
    # We iterate over the unique raw labels present in the dataset (or the map)

    # Create a reverse lookup for the whole array is faster using numpy masks
    dataset_indices = np.arange(len(dataset))

    selected_indices = []

    for raw_label, internal_idx in rev_label_map.items():
        # Find all indices in the dataset that have this raw_label
        # raw_labels can be int64 or one-hot (float32). ImageFolderDataset _load_raw_labels returns int64 or float32.
        # Based on dataset.py, it returns (N,) int64 for categorical.

        class_mask = raw_labels == raw_label
        available_indices = dataset_indices[class_mask]

        # If we need more samples than available, we might need to replace=True
        replace = len(available_indices) < sampling

        # Randomly sample indices for this class
        if len(available_indices) > 0:
            chosen = np.random.choice(available_indices, sampling, replace=replace)
            selected_indices.extend(chosen)
        else:
            print(f"Warning: No samples found for class {raw_label} (internal {internal_idx})")

    # Create a Subset and DataLoader
    # This allows us to use multiple workers to load images (I/O + decode) in parallel
    subset = Subset(dataset, selected_indices)

    # We need a custom collate or just iterate the loader.
    loader = DataLoader(subset, batch_size=128, shuffle=False, num_workers=num_workers, pin_memory=True)

    batch_list = []
    for images, _ in loader:
        # Normalize to [-1, 1]
        images = images.to(torch.float32) / 127.5 - 1
        batch_list.append(images)

    if not batch_list:
        return torch.tensor([])

    return torch.cat(batch_list, dim=0)


def get_synthetic_samples(pool, classes, num_samples):
    samples_list = []

    for class_idx in classes:
        # pool[class_idx] is a tensor of shape [Total_N, H, W, C] (NHWC)
        class_pool = pool[class_idx]
        total_available = class_pool.shape[0]

        # Randomly select indices
        # If we request more than available, we must replace.
        replace = num_samples > total_available
        selected_indices = np.random.choice(total_available, num_samples, replace=replace)

        # Index directly into the tensor (fast)
        selected_batch = class_pool[selected_indices]  # [num_samples, H, W, C]

        # Permute to [num_samples, C, H, W] (NCHW) expected by the judge model
        selected_batch = selected_batch.permute(0, 3, 1, 2)

        samples_list.append(selected_batch)

    return torch.cat(samples_list, dim=0)


parser = argparse.ArgumentParser(description="Hyperspectral Image Classification")

# fmt: off
parser.add_argument("--network-pkl",        help="Model to use",                                                                type=str, required=True)
parser.add_argument("--patch-size",         help="Patch size",                                                                  type=int, default=32)
parser.add_argument("--fid-model-path",     help="Model to calculate FID",                                                      type=str, default=None)
# Pool size parameter
parser.add_argument("--pool-size",          help="Pool size for the generated images",                                          type=int, default=200)
# Dataset parameters
parser.add_argument("--input-path",         help="Path to the input multispectral dataset",                                     type=str, default="./data")
parser.add_argument("--filename",           help="Base filename (without extension)",                                           type=str, required=True)
parser.add_argument("--dataset-seed",       help="Random seed for dataset splitting",                                           type=int, default=0)

parser.add_argument("--batch-size_load",    help="Batch size for data loaders",                                                 type=int, default=256)
parser.add_argument("--batch-size_gen",     help="Batch size for image generation",                                             type=int, default=64)
parser.add_argument("--batch-size-metrics", help="Batch size for metric calculation",                                           type=int, default=64)

parser.add_argument("--synthetic-norm",     help="Wheter to normalize the synthetic images or not",                             action="store_true", default=False)
parser.add_argument("--show-pool-stats",    help="Wheter to show the pool statistics or not",                                   action="store_true", default=False)
parser.add_argument("--num-gpus",           help="Number of GPUs to use (default: all available)",                              type=int, default=None)
# fmt: on

args = parser.parse_args()

device = get_device()
cuda = device.type == "cuda"

SEED = 42
ensure_reproducibility(seed=SEED)

if args.num_gpus is None:
    num_gpus = torch.cuda.device_count()
else:
    num_gpus = args.num_gpus

if num_gpus > torch.cuda.device_count():
    print(
        f"Warning: Requested {num_gpus} GPUs, but only {torch.cuda.device_count()} are available. Using all available GPUs."
    )
    num_gpus = torch.cuda.device_count()
else:
    print(f"Using {num_gpus} GPUs for calculations.")


##########################################################################################
# -------------------------------------- DATA LOADING ---------------------------------- #
##########################################################################################

input_dir = os.path.join(args.input_path, args.filename)
output_dir = os.path.join(args.input_path, args.filename, "patches")

# Build datasets
datasets = dict()
for split_key in ["train", "val", "test"]:
    # Build file names for datasets zips
    dataset_seed_suffix = "" if args.dataset_seed == 0 else f"_{args.dataset_seed}"
    dataset_zip_path = os.path.join(input_dir, f"{args.filename}_{split_key}{dataset_seed_suffix}.zip")
    # Initialize dataset kwargs
    dataset_kwargs, _ = init_dataset_kwargs(data=dataset_zip_path)
    dataset_kwargs.use_label_map = True
    # Build dataset and dataloader
    datasets[split_key], _ = build_dataset(
        dataset_kwargs=dataset_kwargs,
        data_loader_kwargs=dnnlib.EasyDict(),
        batch_size=args.batch_size_load,
    )

# {<index>: <label> - 1}; <index> between 0 and num_classes - 1; <label> true label in the dataset
label_map = datasets["train"].get_label_map()


##########################################################################################
# ------------------------- EXAMPLES OF SYNTHETIC GENERATIONS -------------------------- #
##########################################################################################

class_labels = list(label_map.values())

sample_out_dir = "./out/samples"
os.makedirs(sample_out_dir, exist_ok=True)

_ = generate_images.callback(
    network_pkl=args.network_pkl,
    seeds=[0],  # use always the same seed for reproducibility
    truncation_psi=1.0,
    noise_mode="const",
    outdir=sample_out_dir,
    translate=(0.0, 0.0),
    rotate=0.0,
    class_idx=None,  # no used
    classes=class_labels,
    num_images_per_class=10,
    save_images=True,
    no_rgb=False,
    no_int8=False,
    batch_size=args.batch_size_gen,
    num_gpus=num_gpus,
)

##########################################################################################
# ---------------------------------- IMAGE POOL GENERATION ----------------------------- #
##########################################################################################

samples = generate_images.callback(
    network_pkl=args.network_pkl,
    seeds=[SEED],  # use always the same seed for reproducibility
    truncation_psi=1.0,
    noise_mode="const",
    outdir=sample_out_dir,  # no used as save_images is False
    translate=(0.0, 0.0),
    rotate=0.0,
    class_idx=None,  # no used
    classes=class_labels,
    num_images_per_class=args.pool_size,
    save_images=False,
    no_rgb=True,
    no_int8=True,
    batch_size=args.batch_size_gen,
    num_gpus=num_gpus,
)

# Save the samples in a dictionary, one key for each class
pool = dict()
for i, class_idx in enumerate(class_labels):
    pool[class_idx] = samples[i * args.pool_size : (i + 1) * args.pool_size, :, :, :]

if args.show_pool_stats or args.synthetic_norm:
    # Compute pools stats, i.e., mean and std of the pool
    pool_mean = samples.mean().item()
    pool_var = samples.var().item()
    pool_std = np.sqrt(pool_var)
    print("-" * 20 + "\nPool stats:")
    print(f"Mean: {pool_mean:.6f}")
    print(f"Std: {pool_std:.6f}")

    # Compute real dataset stats, i.e., mean and std of the real dataset
    means = {"train": 0, "test": 0}
    vars = {"train": 0, "test": 0}
    stds = {"train": 0, "test": 0}

    for split in ["train", "test"]:
        for image, label in datasets[split]:
            image = image.astype(np.float32) / 127.5 - 1  # Normalize image to [-1, 1]
            means[split] += image.mean()
        means[split] = means[split] / len(datasets[split])
        for image, label in datasets[split]:
            image = image.astype(np.float32) / 127.5 - 1  # Normalize image to [-1, 1]
            vars[split] += (image.mean() - means[split]) ** 2
        vars[split] = vars[split] / len(datasets[split])
        stds[split] = np.sqrt(vars[split])
        print("-" * 20 + f"\n{split.capitalize()} set stats:")
        print(f"Mean: {means[split]:.6f}")
        print(f"Std: {stds[split]:.6f}")

    scale_factor = stds["train"] / pool_std
    shift = pool_mean - means["train"]
    print("-" * 20 + f"\nShift: {shift:.6f}")
    print(f"Scale factor: {scale_factor:.6f}")

    if args.synthetic_norm:
        # Normalize the image pool
        for class_idx in pool.keys():
            pool[class_idx] = (pool[class_idx] - shift) * scale_factor

        # Concatenate all samples to compute the new stats
        normalized_samples = torch.cat(list(pool.values()), dim=0)
        pool_mean = normalized_samples.mean().item()
        pool_var = normalized_samples.var().item()
        pool_std = np.sqrt(pool_var)
        print("Pool NORMALIZED stats")
        print("Pool stats:")
        print(f"Mean: {pool_mean:.6f}")
        print(f"Std: {pool_std:.6f}")


##########################################################################################
# --------------------------------- LOAD JUDGE MODEL ----------------------------------- #
##########################################################################################

# Load the serialized torch object (judge model)
judge_model = CNN2D_Residual(DatasetMock(), device, HYPERPARAMS)
judge_model.load_state_dict(torch.load(args.fid_model_path, map_location=device))
judge_model.to(device)
judge_model.eval()

if num_gpus > 1:
    print(f"Using {num_gpus} GPUs for metric calculation.")
    judge_model = torch.nn.DataParallel(judge_model)

##########################################################################################
# ------------------------------------ COMPUTE FID ------------------------------------- #
##########################################################################################


print("-" * 20)

sampling_fid = args.pool_size // 2
assert (
    sampling_fid <= args.pool_size
), f"Sampling ({sampling_fid}) must be less or equal than pool size ({args.pool_size})"

experiments_fid = 5

fid_results = []
fid_times = []

for i in tqdm(range(experiments_fid), desc="FID Experiments"):
    start = time.time()

    examples_1 = get_train_samples(datasets["train"], sampling_fid)
    examples_2 = get_synthetic_samples(pool, class_labels, sampling_fid)

    fid_results.append(
        calculate_fid(judge_model, examples_1, examples_2, batch_size=args.batch_size_metrics, device=device)
    )
    fid_times.append(time.time() - start)


##########################################################################################
# ---------------------------- COMPUTE PRECISION AND RECALL -----------------------------#
##########################################################################################


print("-" * 20)

sampling_pr = args.pool_size
assert (
    sampling_pr <= args.pool_size
), f"Sampling ({sampling_pr}) must be less or equal than pool size ({args.pool_size})"

experiments_pr = 5

times_mean = []
times_std = []

precision_results = []
recall_results = []
precision_recall_times = []

for i in tqdm(range(experiments_pr), desc="Precision/Recall Experiments"):
    start = time.time()

    examples_1 = get_train_samples(datasets["train"], sampling_pr)
    examples_2 = get_synthetic_samples(pool, class_labels, sampling_pr)

    # Extract features using the judge model
    features_1 = []
    features_2 = []

    precision, recall = compute_precision_recall(
        judge_model, examples_1, examples_2, batch_size=args.batch_size_metrics, device=device, num_gpus=num_gpus
    )

    precision_results.append(precision)
    recall_results.append(recall)
    precision_recall_times.append(time.time() - start)

##########################################################################################
# ------------------------------------- SHOW RESULTS ----------------------------------- #
##########################################################################################

# Show the results
print("-" * 20 + "\nFinal results:")
print(f"FID: {np.mean(fid_results):.6f} +/- {np.std(fid_results):.6f}")
print(f"Time: {np.mean(fid_times):.6f} +/- {np.std(fid_times):.6f}")
print(f"Precision: {np.mean(precision_results):.6f} +/- {np.std(precision_results):.6f}")
print(f"Recall: {np.mean(recall_results):.6f} +/- {np.std(recall_results):.6f}")
print(f"Time: {np.mean(precision_recall_times):.6f} +/- {np.std(precision_recall_times):.6f}")
