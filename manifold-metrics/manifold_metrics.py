# This code is part of the EMViT-DDPM project and was authored by Victor Barreiro.


"""
This script evaluates the quality of synthetic hyperspectral images generated by a diffusion model.
It calculates FrÃ©chet Inception Distance (FID), Precision, and Recall metrics by comparing
a pool of generated images against a real dataset.

The script performs the following steps:
1.  Parses command-line arguments to configure the evaluation (e.g., model path, dataset, generation parameters).
2.  Loads the specified hyperspectral dataset and a pre-trained diffusion model.
3.  Sets up an experiment folder to save results and logs.
4.  Generates a set of synthetic image examples for visual inspection.
5.  Creates a larger pool of synthetic images for quantitative evaluation.
6.  Optionally normalizes the synthetic data to match the statistical properties (mean, std) of the real data.
7.  If a model for FID is provided, it calculates the FID score between real and synthetic samples.
8.  Calculates k-NN based Precision and Recall to assess the fidelity and diversity of the generated samples.
9.  Logs all configurations, results, and statistics to a file.
"""

##########################################################################################
# ------------------------------------ GLOBAL IMPORTS ----------------------------------#
##########################################################################################


# Basic SO imports
import argparse
import multiprocessing
import os
import pickle
import random
import sys
import time

# Basic ML imports
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
from classifiers.networks import *

# Custom imports
from data_managment_hsiml.data_managment_hsiml import *
from diffusion.diffusion_datasets import *
from diffusion.diffusion_generation import *
from torchvision.utils import make_grid, save_image
from tqdm import tqdm


# Time control
def now():
    """Returns the current time as a formatted string."""
    return time.strftime("%Y-%m-%d %H:%M:%S")


# Create the parser
parser = argparse.ArgumentParser(description="Hyperspectral Image Classification")

# Add arguments
parser.add_argument("--model_path", type=str, default="None", help="Model to use")
parser.add_argument("--type", type=str, default="DiT_S_2", help="Diffusion architecture to use")
parser.add_argument("--patch_size", type=int, default=32, help="Patch size")
# Fid
parser.add_argument("--FID", type=str, default="None", help="Model to calculate FID")

parser.add_argument("--cfg_scale", type=float, default=1, help="cfg_scale for noise generation in the diffusion model")
parser.add_argument(
    "--num_sampling_steps", type=int, default=250, help="num_sampling_steps for noise generation in the diffusion model"
)

# Normalize
parser.add_argument("--normalize", type=int, default=-1, help="Normalization applied")

# Pool size parameter
parser.add_argument("--pool_size", type=int, default=200, help="Pool size for the generated images")
# Path pool
parser.add_argument(
    "--pool_path",
    type=str,
    default="None",
    help="Path to the pool of images. If there is one to use in place to generate it.",
)

# Dataset parameter
parser.add_argument("--dataset", type=str, required=True, help="Dataset to use")

# Synthethicnormalization  0 for False, 1 for True
parser.add_argument(
    "--synthetic_normalization",
    type=int,
    default=0,
    help="Normalization for the synthetic generation: 1 for True, 0 for False",
)


##########################################################################################
# ------------------------------------ GPU ACCES CHECK ----------------------------------#
##########################################################################################

GPU = True  # Could be disable for resarch proposes but the requiring time to execute without GPU is too high
if GPU:
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    cuda = True
else:
    device = torch.device("cpu")

print(f"{now()} - Device: {device}")

##########################################################################################
# ------------------------------ SEEDs FOR REPRODUCIBILITY ------------------------------#
##########################################################################################

SEED = 0
torch.manual_seed(SEED)
np.random.seed(SEED)
random.seed(SEED)

if cuda == False:
    torch.use_deterministic_algorithms(True)
    g = torch.Generator()
    g.manual_seed(SEED)
else:
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

##########################################################################################
# -------------------------------------- DATA LOADING -----------------------------------#
##########################################################################################

print(f"{now()} - Loading data")
if parser.parse_args().dataset == "eiras":
    DATASET = "../images/eiras_dam.raw"
    GT = "../images/eiras_dam.pgm"
    SEG = "../images/seg_eiras_wp.raw"
    CENTER = "../images/seg_eiras_wp_centers.raw"
elif parser.parse_args().dataset == "oitaven":
    DATASET = "../images/oitaven_river.raw"
    GT = "../images/oitaven_river.pgm"
    SEG = "../images/seg_oitaven_wp.raw"
    CENTER = "../images/seg_oitaven_wp_centers.raw"
elif parser.parse_args().dataset == "ermidas":
    DATASET = "../images/ermidas_creek.raw"
    GT = "../images/ermidas_creek.pgm"
    SEG = "../images/seg_ermidas_wp.raw"
    CENTER = "../images/seg_ermidas_wp_centers.raw"
elif parser.parse_args().dataset == "ferreiras":
    DATASET = "../images/ferreiras_river.raw"
    GT = "../images/ferreiras_river.pgm"
    SEG = "../images/seg_ferreiras_wp.raw"
    CENTER = "../images/seg_ferreiras_wp_centers.raw"
elif parser.parse_args().dataset == "ulla":
    DATASET = "../images/ulla_river.raw"
    GT = "../images/ulla_river.pgm"
    SEG = "../images/seg_ulla_wp.raw"
    CENTER = "../images/seg_ulla_wp_centers.raw"
elif parser.parse_args().dataset == "mera":
    DATASET = "../images/mera_river.raw"
    GT = "../images/mera_river.pgm"
    SEG = "../images/seg_mera_wp.raw"
    CENTER = "../images/seg_mera_wp_centers.raw"
elif parser.parse_args().dataset == "xesta":
    DATASET = "../images/xesta_basin.raw"
    GT = "../images/xesta_basin.pgm"
    SEG = "../images/seg_xesta_wp.raw"
    CENTER = "../images/seg_xesta_wp_centers.raw"
elif parser.parse_args().dataset == "mestas":
    DATASET = "../images/das_mestas_river.raw"
    GT = "../images/das_mestas_river.pgm"
    SEG = "../images/seg_mestas_wp.raw"
    CENTER = "../images/seg_mestas_wp_centers.raw"
else:
    print("Dataset not found")
    exit()

start = time.time()

# Load data
(datos, width, height, bands, unnormalized_data) = read_raw(DATASET, parser.parse_args().normalize)
(truth, width_1, height_1) = read_pgm(GT)
(seg, width_2, height_2) = read_seg(SEG)
(center, width_3, height_3, nseg) = read_seg_centers(CENTER)

bands = 5
nclases = 10

model_path = parser.parse_args().model_path

patch_size = parser.parse_args().patch_size
p_train = 0.15
p_val = 0.05
(train_set, validation_set, test_set, nclases, _) = select_training_samples_seg(
    truth, center, width, height, patch_size, patch_size, [p_train, p_val]
)


# Load experiment data
train_set = pickle.load(open(model_path + "/train_set.pickle", "rb"))
validation_set = pickle.load(open(model_path + "/validation_set.pickle", "rb"))
test_set = pickle.load(open(model_path + "/test_set.pickle", "rb"))

patch_size = parser.parse_args().patch_size
dataset_train = HyperDataset(datos, truth, train_set, width, height, bands, patch_size)
dataset_val = HyperDataset(datos, truth, validation_set, width, height, bands, patch_size)
dataset_test = HyperDataset(datos, truth, test_set, width, height, bands, patch_size)

non_empty_classes = set()
for patch, label in dataset_train:
    if label not in non_empty_classes:
        non_empty_classes.add(label)
    if len(non_empty_classes) == nclases:
        break
non_empty_classes = list(non_empty_classes)


##########################################################################################
# ------------------------------------ DIFFUSION MODEL ----------------------------------#
##########################################################################################

image_size = patch_size  # In our RS pipline a patch is an image for the diffusion model
# Should be hilghted that the ViT models uses a internal paramiter called patch_size

##########################################################################################
# ------------------------------------ Diffusion Setup -----------------------------------#
##########################################################################################

print("Classes for the model: ", nclases)
print(f"{now()} - Creating diffusion model")
model_class = getattr(__import__("diffusion.models", fromlist=[parser.parse_args().type]), parser.parse_args().type)
model = model_class(
    input_size=image_size,
    num_classes=nclases,
    in_channels=bands,
).to(device)

print(f"{now()} - Loading weights")
checkpoint_path = model_path + "/checkpoints/"
checkpoint_path = checkpoint_path + "final.pt"
model.load_state_dict(torch.load(checkpoint_path)["ema"])
model.eval()

##########################################################################################
# ------------------------------- EXPERIMENT PREPARATION --------------------------------#
##########################################################################################
arguments = parser.parse_args()
print(f"{now()} - Preparing experiment")
EXPERIMENT_FOLDER = (
    f"{model_path}/metrics_"
    f"cfg_scale_{arguments.cfg_scale}_num_sampling_steps_{arguments.num_sampling_steps}"
    f"synthetic_normalization_{arguments.synthetic_normalization}_poolsize_{arguments.pool_size}/"
)


print(f"{now()} - Experiment folder: {EXPERIMENT_FOLDER}")

if not os.path.exists(EXPERIMENT_FOLDER):
    os.makedirs(EXPERIMENT_FOLDER)
log_file = open(EXPERIMENT_FOLDER + "log.txt", "w")
print(f"{now()} - Redirecting the output to log file. File: {EXPERIMENT_FOLDER + 'log.txt'}")
sys.stdout = log_file

print(f"{now()} - Parameters:")
print(parser.parse_args())
print(" - training dataset:", len(dataset_train))
for i in range(nclases):
    print("   - class", i, ":", len([x for x in dataset_train if x[1] == i]))
print(" - validation dataset:", len(dataset_val))
for i in range(nclases):
    print("   - class", i, ":", len([x for x in dataset_val if x[1] == i]))
print(" - test dataset:", len(dataset_test))
for i in range(nclases):
    print("   - class", i, ":", len([x for x in dataset_test if x[1] == i]))
print("non_empty_classes:", non_empty_classes)


##########################################################################################
# ------------------------- EXAMPLES OF SYNTHETIC GENERATIONS ---------------------------#
##########################################################################################

print(f"{now()} - Generating synthetic examples")
class_labels = []
number_of_samples = 36
print(non_empty_classes)
for i in non_empty_classes:
    for j in range(number_of_samples):
        class_labels.append(i)

samples = generate_diffusion_samples(
    model,
    class_labels,
    bands,
    nclases,
    num_sampling_steps=arguments.num_sampling_steps,
    cfg_scale=arguments.cfg_scale,
    device=device,
)
show_samples(
    samples,
    non_empty_classes,
    number_of_samples,
    EXPERIMENT_FOLDER,
    normalization=arguments.normalize,
    save=True,
    raw=False,
)
del samples

##########################################################################################
# ---------------------------------- IMAGE POOL GENERATION ------------------------------#
##########################################################################################

print(f"{now()} - Generating synthetic samples pool")
class_labels = []
number_of_samples = arguments.pool_size
for i in non_empty_classes:
    for j in range(number_of_samples):
        class_labels.append(i)

samples = generate_diffusion_samples(
    model,
    class_labels,
    bands,
    nclases,
    num_sampling_steps=arguments.num_sampling_steps,
    cfg_scale=arguments.cfg_scale,
    device=device,
)
# Save the samples in a dictionary, one key for each class
pool = dict()
for i in range(len(non_empty_classes)):
    same_class = []
    for j in range(number_of_samples):
        same_class.append(samples[i * number_of_samples + j])
    pool[non_empty_classes[i]] = same_class

print(f"{now()} - Pool completed")
print("Pool keys", pool.keys())
print("Pool generated")

# pickle.dump(pool, open(EXPERIMENT_FOLDER + "pool.pickle", "wb"))

print("Pool stats")
mean = 0
for i in range(len(non_empty_classes)):
    for j in range(number_of_samples):
        mean += pool[non_empty_classes[i]][j].mean()
mean = mean / (len(non_empty_classes) * number_of_samples)
var = 0
for i in range(len(non_empty_classes)):
    for j in range(number_of_samples):
        var += (pool[non_empty_classes[i]][j].mean() - mean) ** 2
var = var / (len(non_empty_classes) * number_of_samples)

print("Mean: ", mean)
print("Std: ", np.sqrt(var))
pool_mean = mean
pool_std = np.sqrt(var)

# Mean and std of the train set, to normalize the pool
mean = 0
for i in range(len(dataset_train)):
    mean += dataset_train[i][0].mean()
mean = mean / len(dataset_train)
var = 0
for i in range(len(dataset_train)):
    var += (dataset_train[i][0].mean() - mean) ** 2
var = var / len(dataset_train)
print("Train set stats:")
print("Mean: ", mean)
print("Std: ", np.sqrt(var))

real_mean = mean
real_std = np.sqrt(var)

mean = 0
for i in range(len(dataset_test)):
    mean += dataset_test[i][0].mean()
mean = mean / len(dataset_test)
var = 0
for i in range(len(dataset_test)):
    var += (dataset_test[i][0].mean() - mean) ** 2
var = var / len(dataset_test)
print("Test set stats:")
print("Mean: ", mean)
print("Std: ", np.sqrt(var))

scale_factor = real_std / pool_std
shift = pool_mean - real_mean
print("Scale factor: ", scale_factor)
print("Shift: ", shift)

if parser.parse_args().synthetic_normalization == 1:
    # Normalize the image pool
    for i in range(10):
        for j in range(number_of_samples):
            pool[i][j] = (pool[i][j] - shift) * scale_factor

print("Pool NORMALIZED stats")
mean = 0
for i in non_empty_classes:
    for j in range(number_of_samples):
        mean += pool[i][j].mean()
mean = mean / (len(non_empty_classes) * number_of_samples)

var = 0
for i in non_empty_classes:
    for j in range(number_of_samples):
        var += (pool[i][j].mean() - mean) ** 2
var = var / (len(non_empty_classes) * number_of_samples)

print("Mean: ", mean)
print("Std: ", np.sqrt(var))
pool_mean = mean
pool_std = np.sqrt(var)

##########################################################################################
# ------------------------------------ CALCULATE THE FID ---------------------------------#
##########################################################################################


if parser.parse_args().FID != "None":
    # Load the serialized object with torch judge.pt
    judge_model = torch.load(parser.parse_args().FID)
    judge_model.to(device)

    import matplotlib.pyplot as plt

    print("Calculating FID")

    sampling = 100

    experiments = 5

    fids = []
    times = []

    for i in range(experiments):
        examples_1 = []
        examples_2 = []
        start = time.time()

        # Set a counter per class with double the sampling value
        counter = [sampling] * len(non_empty_classes)

        # Iterate through the dataset saving the indices of each class separately
        class_indexes = [[] for i in non_empty_classes]
        print("class_indexes: ", len(class_indexes))
        # Start at a random index and move through the set until the data is covered
        i = np.random.randint(0, len(dataset_train))
        while sum(counter) != 0:
            pos = non_empty_classes.index(dataset_train[i][1])
            if counter[pos] > 0:
                class_indexes[pos].append(i)
                counter[pos] -= 1
            i = (i + 1) % len(dataset_train)

        # Add the elements from the indices to the example set
        for i in range(len(non_empty_classes)):
            for j in class_indexes[i]:
                examples_1.append(dataset_train[j][0])

        # Now we take samples from the pool
        for i in range(len(non_empty_classes)):
            # Get samples from the pool
            samples = obtain_samples_from_pool(pool, [non_empty_classes[i]], sampling)
            # We only keep the images without labels and convert them to torch tensors
            new_samples = []
            for sample in samples:
                s = sample[0]
                # s = torch.tensor(s).to(device)
                new_samples.append(s)
            samples = new_samples

            # Add the samples to the example set
            examples_2.extend(samples)

        fids.append(calculate_fid(judge_model, examples_1, examples_2, device="cpu"))
        end = time.time()
        times.append(end - start)

    # Show the results
    print("FID: ", np.mean(fids), " +/- ", np.std(fids))
    print("Time: ", np.mean(times), " +/- ", np.std(times))


##########################################################################################
# ----------------------------------- Precision and Recall -------------------------------#
##########################################################################################


def batch_pairwise_distances(U, V):
    """
    Compute pairwise distances between two batches of feature vectors.

    Args:
        U (torch.Tensor): A batch of feature vectors of shape (N, F).
        V (torch.Tensor): A batch of feature vectors of shape (M, F).

    Returns:
        torch.Tensor: A distance matrix of shape (N, M).
    """
    norm_u = torch.sum(U**2, dim=1, keepdim=True)
    norm_v = torch.sum(V**2, dim=1, keepdim=True).t()
    D = torch.clamp(norm_u - 2 * torch.mm(U, V.t()) + norm_v, min=0.0)
    return D


# ----------------------------------------------------------------------------


class DistanceBlock:
    """
    Provides multi-GPU support to calculate pairwise distances between two batches of feature vectors.

    Args:
        num_features (int): The number of features in the input vectors.
        num_gpus (int): The number of GPUs to use for computation.
    """

    def __init__(self, num_features, num_gpus):
        self.num_features = num_features
        self.num_gpus = num_gpus

    def pairwise_distances(self, U, V):
        """
        Evaluate pairwise distances between two batches of feature vectors.

        Args:
            U (torch.Tensor): A batch of feature vectors.
            V (torch.Tensor): A batch of feature vectors.

        Returns:
            torch.Tensor: A tensor containing the pairwise distances.
        """
        U_split = torch.split(U, U.shape[0] // self.num_gpus)
        V_split = torch.split(V, V.shape[0] // self.num_gpus)

        distances_split = []
        for i in range(self.num_gpus):
            with torch.cuda.device(i):
                distances_split.append(batch_pairwise_distances(U_split[i].cuda(), V_split[i].cuda()).cpu())

        return torch.cat(distances_split, dim=1)


# ----------------------------------------------------------------------------


class ManifoldEstimator:
    """
    Estimates the manifold of given feature vectors by calculating k-NN distances.

    This class computes the distances to the k-nearest neighbors for each feature vector
    in a reference set, which defines the manifold. It can then be used to evaluate
    whether new feature vectors fall within this manifold.

    Args:
        distance_block (DistanceBlock): An object to compute pairwise distances.
        features (np.ndarray): The reference feature vectors.
        row_batch_size (int): Batch size for rows in distance calculation.
        col_batch_size (int): Batch size for columns in distance calculation.
        nhood_sizes (list[int]): A list of k values for k-NN.
        clamp_to_percentile (float, optional): If specified, clamps distances to a given percentile.
        eps (float): A small epsilon value to avoid division by zero.
    """

    def __init__(
        self,
        distance_block,
        features,
        row_batch_size=25000,
        col_batch_size=50000,
        nhood_sizes=[3],
        clamp_to_percentile=None,
        eps=1e-5,
    ):
        """Estimate the manifold of given feature vectors."""
        num_images = features.shape[0]
        self.nhood_sizes = nhood_sizes
        self.num_nhoods = len(nhood_sizes)
        self.eps = eps
        self.row_batch_size = row_batch_size
        self.col_batch_size = col_batch_size
        self._ref_features = torch.tensor(features, dtype=torch.float32)
        self._distance_block = distance_block

        # Estimate manifold of features by calculating distances to k-NN of each sample.
        self.D = np.zeros([num_images, self.num_nhoods], dtype=np.float32)
        distance_batch = np.zeros([row_batch_size, num_images], dtype=np.float32)
        seq = np.arange(max(self.nhood_sizes) + 1, dtype=np.int32)

        for begin1 in range(0, num_images, row_batch_size):
            end1 = min(begin1 + row_batch_size, num_images)
            row_batch = self._ref_features[begin1:end1]

            for begin2 in range(0, num_images, col_batch_size):
                end2 = min(begin2 + col_batch_size, num_images)
                col_batch = self._ref_features[begin2:end2]

                # Compute distances between batches.
                distance_batch[0 : end1 - begin1, begin2:end2] = self._distance_block.pairwise_distances(
                    row_batch, col_batch
                ).numpy()

            # Find the k-nearest neighbor from the current batch.
            self.D[begin1:end1, :] = np.partition(distance_batch[0 : end1 - begin1, :], seq, axis=1)[
                :, self.nhood_sizes
            ]

        if clamp_to_percentile is not None:
            max_distances = np.percentile(self.D, clamp_to_percentile, axis=0)
            self.D[self.D > max_distances] = 0

    def evaluate(self, eval_features, return_realism=False, return_neighbors=False):
        """
        Evaluate if new feature vectors are within the estimated manifold.

        Args:
            eval_features (np.ndarray): The feature vectors to evaluate.
            return_realism (bool): Whether to return the realism score.
            return_neighbors (bool): Whether to return the nearest neighbor indices.

        Returns:
            np.ndarray: An array of predictions (1 if in manifold, 0 otherwise).
            (optional) np.ndarray: Realism scores.
            (optional) np.ndarray: Nearest neighbor indices.
        """
        eval_features = torch.tensor(eval_features, dtype=torch.float32)
        num_eval_images = eval_features.shape[0]
        num_ref_images = self.D.shape[0]
        distance_batch = np.zeros([self.row_batch_size, num_ref_images], dtype=np.float32)
        batch_predictions = np.zeros([num_eval_images, self.num_nhoods], dtype=np.int32)
        max_realism_score = np.zeros(
            [
                num_eval_images,
            ],
            dtype=np.float32,
        )
        nearest_indices = np.zeros(
            [
                num_eval_images,
            ],
            dtype=np.int32,
        )

        for begin1 in range(0, num_eval_images, self.row_batch_size):
            end1 = min(begin1 + self.row_batch_size, num_eval_images)
            feature_batch = eval_features[begin1:end1]

            for begin2 in range(0, num_ref_images, self.col_batch_size):
                end2 = min(begin2 + self.col_batch_size, num_ref_images)
                ref_batch = self._ref_features[begin2:end2]

                distance_batch[0 : end1 - begin1, begin2:end2] = self._distance_block.pairwise_distances(
                    feature_batch, ref_batch
                ).numpy()

            # From the minibatch of new feature vectors, determine if they are in the estimated manifold.
            samples_in_manifold = distance_batch[0 : end1 - begin1, :, None] <= self.D
            batch_predictions[begin1:end1] = np.any(samples_in_manifold, axis=1).astype(np.int32)

            max_realism_score[begin1:end1] = np.max(
                self.D[:, 0] / (distance_batch[0 : end1 - begin1, :] + self.eps), axis=1
            )
            nearest_indices[begin1:end1] = np.argmin(distance_batch[0 : end1 - begin1, :], axis=1)

        if return_realism and return_neighbors:
            return batch_predictions, max_realism_score, nearest_indices
        elif return_realism:
            return batch_predictions, max_realism_score
        elif return_neighbors:
            return batch_predictions, nearest_indices

        return batch_predictions


# ----------------------------------------------------------------------------


def knn_precision_recall_features(
    ref_features, eval_features, nhood_sizes=[3], row_batch_size=10000, col_batch_size=50000, num_gpus=1
):
    """
    Calculates k-NN precision and recall for two sets of feature vectors.

    Args:
        ref_features (np.ndarray): Reference feature vectors (e.g., from real data).
        eval_features (np.ndarray): Evaluation feature vectors (e.g., from generated data).
        nhood_sizes (list[int]): List of k values for k-NN.
        row_batch_size (int): Batch size for rows in distance calculation.
        col_batch_size (int): Batch size for columns in distance calculation.
        num_gpus (int): Number of GPUs to use.

    Returns:
        dict: A dictionary containing 'precision' and 'recall' arrays.
    """
    state = dict()
    num_images = ref_features.shape[0]
    num_features = ref_features.shape[1]

    # Initialize DistanceBlock and ManifoldEstimators.
    distance_block = DistanceBlock(num_features, num_gpus)
    ref_manifold = ManifoldEstimator(distance_block, ref_features, row_batch_size, col_batch_size, nhood_sizes)
    eval_manifold = ManifoldEstimator(distance_block, eval_features, row_batch_size, col_batch_size, nhood_sizes)

    # Evaluate precision and recall using k-nearest neighbors.
    print("Evaluating k-NN precision and recall with %i samples..." % num_images)
    start = time.time()

    # Precision: How many points from eval_features are in ref_features manifold.
    precision = ref_manifold.evaluate(eval_features)
    state["precision"] = precision.mean(axis=0)
    print("Precision:", state["precision"])

    # Recall: How many points from ref_features are in eval_features manifold.
    recall = eval_manifold.evaluate(ref_features)
    state["recall"] = recall.mean(axis=0)
    print("Recall:", state["recall"])

    print("Evaluated k-NN precision and recall in: %gs" % (time.time() - start))

    return state


##########################################################################################
# ---------------------------- CALCULATE PRECISION AND RECALL --------------------------#
##########################################################################################

experiments = 5

precision_mean = []
recall_mean = []
precision_std = []
recall_std = []

times_mean = []
times_std = []

sampling = 200

results_precission = []
results_recall = []
result_times = []

# Load the serialized torch object (judge model)
judge_model = torch.load(parser.parse_args().FID)
judge_model.to(device)

for i in range(experiments):
    examples_1 = []
    examples_2 = []
    start = time.time()

    # Set a counter for each class
    counter = [sampling] * len(non_empty_classes)

    # Iterate through the dataset, saving indices for each class separately
    class_indexes = [[] for i in non_empty_classes]
    print("class_indexes: ", len(class_indexes))
    # Start at a random index and loop through the dataset to gather samples
    i = np.random.randint(0, len(dataset_train))
    while sum(counter) != 0:
        pos = non_empty_classes.index(dataset_train[i][1])
        if counter[pos] > 0:
            class_indexes[pos].append(i)
            counter[pos] -= 1
        i = (i + 1) % len(dataset_train)

    # Add elements from the collected indices to the example set 1 (real data)
    for i in range(len(non_empty_classes)):
        for j in class_indexes[i]:
            examples_1.append(dataset_train[j][0])

    # Now, take samples from the generated pool for example set 2 (synthetic data)
    for i in range(len(non_empty_classes)):
        # Get samples from the pool
        samples = obtain_samples_from_pool(pool, [non_empty_classes[i]], sampling)
        # Keep only the images (not labels) and convert to torch tensor
        new_samples = []
        for sample in samples:
            s = sample[0]
            # s = torch.tensor(s).to(device)
            new_samples.append(s)
        samples = new_samples

        # Add the synthetic samples to the example set
        examples_2.extend(samples)

    # Extract features using the judge model
    features_1 = []
    features_2 = []

    # Disable gradient calculation for inference
    with torch.no_grad():
        examples_1 = torch.stack(examples_1)
        examples_1 = examples_1.to(device)
        _, features = judge_model(examples_1)
        features_1 = features.cpu().numpy()

        examples_2 = torch.stack(examples_2)
        examples_2 = examples_2.to(device)
        _, features = judge_model(examples_2)
        features_2 = features.cpu().numpy()

    state = knn_precision_recall_features(features_1, features_2, row_batch_size=10000, col_batch_size=50000)
    precision = state["precision"][0]
    recall = state["recall"][0]

    results_precission.append(precision)
    results_recall.append(recall)
    result_times.append(time.time() - start)


print("Precision: ", np.mean(results_precission), " +/- ", np.std(results_precission))
print("Recall: ", np.mean(results_recall), " +/- ", np.std(results_recall))

print("Time: ", np.mean(result_times), " +/- ", np.std(result_times))

##########################################################################################

# Close the log file when finished
log_file.close()
